---
title: "Machine Learning 1"
author: 'Shivani Khosla (PID: A59010433)'
date: "10/22/2021"
output: github_document
---

# Clustering methods

Kmeans clustering in R is done with the 'kmeans()' function. Here we make up some data to test and learn with. 

rev reverses order of vector
cbind concatenates the two vectors in tmp
```{r}
tmp <- c(rnorm(30, 3), rnorm(30, -3))
data <- cbind(x = tmp, y = rev(tmp))
plot(data)
```
Run 'kmeans()' set k to 2, nstart to 20. Have to tell it how many clusters you want. 

```{r}
km <- kmeans(data, centers = 2, nstart = 20)
km
```

> Q. How many points are in each cluster?

```{r}
km$size
```

> Q. What 'component' of your result object details cluster assignment/membership?

```{r}
km$cluster
```

> Q. What 'component' of your result object details cluster center?

```{r}
km$centers
```

> Q. Plot x colored by the kmeans cluster assignment and add cluster centers as blue points

```{r}
plot(data, col = km$cluster)
points(km$centers, col = 'blue', pch = 15, cex = 2)
```

# Hierarchical Clustering

Use the 'hclust()' function on the same data as before
```{r}
hc <- hclust(dist(data))
hc
```

hclust has a plot method

```{r}
plot(hc)
```
To find membership vector, need to 'cut' the tree by using 'cutree' function and tell it the height to cut at

```{r}
cutree(hc, h = 7)
```

Use 'cutree()' and sate the number of k clusters we want

```{r}
grps <- cutree(hc, k = 2)
```

```{r}
plot(data, col = grps)
```

# Principal Component Analysis (PCA)

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
```
How many rows and cols?

```{r}
dim(x)
```

```{r}
x[,-1]
```

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url, row.names = 1)
x
```

```{r}
barplot(as.matrix(x), col = rainbow(17), beside = TRUE)
```

```{r}
mycols <- rainbow(nrow(x))
pairs(x, col = mycols, pch = 16)
```

## PCA to the rescue!

Use base R function for PCA, which is called 'prcomp()'. This function wants the transpose of our data. 

```{r}
pca <- prcomp(t(x))
summary(pca)
```

```{r}
plot(pca)
```

We want score plot (aka PCA plot). Basically of PC1 vs PC2

```{r}
attributes(pca)
```

We are after the pca$x component for this plot

```{r}
plot(pca$x[,1:2])
text(pca$x[,1:2], labels = colnames(x))
```

We can also examine the PCA "loadings", which tell us how much the original variables contribute to each PC

```{r}
par(mar=c(10, 3, 0.35, 0))
barplot(pca$rotation[,1], las = 2)
```

## One more PCA for today 

```{r}
url2 <- "https://tinyurl.com/expression-CSV"
rna.data <- read.csv(url2, row.names=1)
head(rna.data)
```
```{r}
nrow(rna.data)
```

```{r}
ncol(rna.data)
```

```{r}
colnames(rna.data)
```

```{r}
pca.rna <- prcomp(t(rna.data), scale = TRUE)
summary(pca.rna)
```

```{r}
plot(pca.rna)
```

```{r}
plot(pca.rna$x[,1:2])
text(pca.rna$x[,1:2], labels = colnames(rna.data))
```

